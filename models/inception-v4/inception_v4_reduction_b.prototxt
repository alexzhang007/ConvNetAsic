name: "Inception v4 Reduction-B"
layer {
  name: "inception_b7_concat"
  type: "Input"
  top: "inception_b7_concat"
  input_param {
      shape: {
          dim: 1
          dim: 1024
          dim: 17
          dim: 17
      }
  }
}
layer {
  name: "reduction_b_pool"
  type: "Pooling"
  bottom: "inception_b7_concat"
  top: "reduction_b_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "reduction_b_3x3_reduce"
  type: "Convolution"
  bottom: "inception_b7_concat"
  top: "reduction_b_3x3_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_reduce_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "reduction_b_3x3_reduce_scale"
  type: "Scale"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_reduce_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3_reduce"
}
layer {
  name: "reduction_b_3x3"
  type: "Convolution"
  bottom: "reduction_b_3x3_reduce"
  top: "reduction_b_3x3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "reduction_b_3x3_scale"
  type: "Scale"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3"
  top: "reduction_b_3x3"
}
layer {
  name: "reduction_b_1x7_reduce"
  type: "Convolution"
  bottom: "inception_b7_concat"
  top: "reduction_b_1x7_reduce"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_1x7_reduce_bn"
  type: "BatchNorm"
  bottom: "reduction_b_1x7_reduce"
  top: "reduction_b_1x7_reduce"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "reduction_b_1x7_reduce_scale"
  type: "Scale"
  bottom: "reduction_b_1x7_reduce"
  top: "reduction_b_1x7_reduce"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_1x7_reduce_relu"
  type: "ReLU"
  bottom: "reduction_b_1x7_reduce"
  top: "reduction_b_1x7_reduce"
}
layer {
  name: "reduction_b_1x7"
  type: "Convolution"
  bottom: "reduction_b_1x7_reduce"
  top: "reduction_b_1x7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
    pad_h: 0
    pad_w: 3
    kernel_h: 1
    kernel_w: 7
  }
}
layer {
  name: "reduction_b_1x7_bn"
  type: "BatchNorm"
  bottom: "reduction_b_1x7"
  top: "reduction_b_1x7"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "reduction_b_1x7_scale"
  type: "Scale"
  bottom: "reduction_b_1x7"
  top: "reduction_b_1x7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_1x7_relu"
  type: "ReLU"
  bottom: "reduction_b_1x7"
  top: "reduction_b_1x7"
}
layer {
  name: "reduction_b_7x1"
  type: "Convolution"
  bottom: "reduction_b_1x7"
  top: "reduction_b_7x1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
    pad_h: 3
    pad_w: 0
    kernel_h: 7
    kernel_w: 1
  }
}
layer {
  name: "reduction_b_7x1_bn"
  type: "BatchNorm"
  bottom: "reduction_b_7x1"
  top: "reduction_b_7x1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "reduction_b_7x1_scale"
  type: "Scale"
  bottom: "reduction_b_7x1"
  top: "reduction_b_7x1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_7x1_relu"
  type: "ReLU"
  bottom: "reduction_b_7x1"
  top: "reduction_b_7x1"
}
layer {
  name: "reduction_b_3x3_2"
  type: "Convolution"
  bottom: "reduction_b_7x1"
  top: "reduction_b_3x3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    pad: 0
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "reduction_b_3x3_2_bn"
  type: "BatchNorm"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "reduction_b_3x3_2_scale"
  type: "Scale"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "reduction_b_3x3_2_relu"
  type: "ReLU"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_3x3_2"
}
layer {
  name: "reduction_b_concat"
  type: "Concat"
  bottom: "reduction_b_pool"
  bottom: "reduction_b_3x3"
  bottom: "reduction_b_3x3_2"
  top: "reduction_b_concat"
}

